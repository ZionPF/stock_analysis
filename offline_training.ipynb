{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 由CSV生成语料库\n",
    "\n",
    "* 读取csv文件\n",
    "* 对于一行资讯进行分词\n",
    "* 将分词结果写入新的txt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常量定义\n",
    "\n",
    "#语料库文件路径：\n",
    "DATA_PATH = '../data/news_words.txt'\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import word_segmentation as ws\n",
    "word_segmentor = ws.WordSegmentation()\n",
    "\n",
    "\n",
    "# write_news_words\n",
    "# 输入 csv 文件的 file_path\n",
    "# 操作：分词-写入DATA_FILE\n",
    "def write_news_words(file_path):\n",
    "    file_data = pd.read_csv(file_path)\n",
    "    file_data.rename(columns={'标题':'title', '正文':'content','正文1':'content',\"字段1_文本\":\"title\"}, inplace = True)\n",
    "    file = open(DATA_PATH,\"a\")\n",
    "    for index, row in file_data.iterrows():\n",
    "        #print(row.content)\n",
    "        row_words = word_segmentor.word_segmentation(str(row.title) + str(row.content))\n",
    "        file_words = \" \".join(row_words)\n",
    "        file.write(file_words + ' \\n')\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "# 添加文件到语料库\n",
    "# 输入：new_path 为新增的抓取csv数据的文件夹\n",
    "# 执行：将csv文件的分词结果写入语料库文件\n",
    "def append_csv2txt(new_path):\n",
    "    files = os.listdir(new_path)\n",
    "    print(files)\n",
    "    \n",
    "    for fname in files:\n",
    "        fpath = new_path + fname\n",
    "        if 'csv' in fpath:\n",
    "            print(fpath)\n",
    "            write_news_words(fpath)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news0312.csv', '东财关键词对应新闻-0426-6.csv', '东方财经关键词板块对应新闻-0425-2.csv', '行业股票频道东方财富网---600621行业要闻-券商信托资讯-0302.csv', '东方财经关键词板块对应新闻-0425-1.csv', '行业股票频道东方财富网---600621行业要闻-券商信托研报-0312-2.csv', '第一财经板块对应新闻-0423-2.csv', '东方财富网---个股要闻(1).csv', '第一财经板块对应新闻-0428-1.csv', '东方财富网---个股要闻-TO603099.csv', '东财关键词对应新闻-0427.csv', '第一财经板块对应新闻-0428-3.csv', '行业股票频道东方财富网---600621行业要闻-券商信托资讯-0305.csv', '行业研究报告数据中心东方财富网-0502-2.csv', '第一财经板块对应新闻-0423-1.csv', '东方财富网---个股要闻-TO600689.csv', '第一财经板块对应新闻-0419-2.csv', '行业研究报告数据中心东方财富网-0502-1.csv', '东财行业板块关键词.csv', '第一财经板块对应新闻-0413.csv', '东财关键词对应新闻-0426-7.csv', '东财关键词对应新闻-0426-4.csv', '东财关键词对应新闻-0426-3.csv', '东财关键词对应新闻-0426-8.csv', '东方财经关键词板块对应新闻-0427.csv', '第一财经板块对应新闻.csv', '第一财经板块对应新闻-0428-2.csv', '东财关键词对应新闻-0426-1.csv', '东方财富网中国财经门户提供专业的财经股票.csv', '第一财经板块对应新闻-0419-1.csv', '东财关键词对应新闻-0426-5.csv', '东财关键词对应新闻-0426-2.csv', '第一财经板块对应新闻-0416.csv', '行业股票频道东方财富网---600621行业要闻-券商信托研报-0312.csv']\n",
      "../news/news0312.csv\n",
      "../news/东财关键词对应新闻-0426-6.csv\n",
      "../news/东方财经关键词板块对应新闻-0425-2.csv\n",
      "../news/行业股票频道东方财富网---600621行业要闻-券商信托资讯-0302.csv\n",
      "../news/东方财经关键词板块对应新闻-0425-1.csv\n",
      "../news/行业股票频道东方财富网---600621行业要闻-券商信托研报-0312-2.csv\n",
      "../news/第一财经板块对应新闻-0423-2.csv\n",
      "../news/东方财富网---个股要闻(1).csv\n",
      "../news/第一财经板块对应新闻-0428-1.csv\n",
      "../news/东方财富网---个股要闻-TO603099.csv\n",
      "../news/东财关键词对应新闻-0427.csv\n",
      "../news/第一财经板块对应新闻-0428-3.csv\n",
      "../news/行业股票频道东方财富网---600621行业要闻-券商信托资讯-0305.csv\n",
      "../news/行业研究报告数据中心东方财富网-0502-2.csv\n",
      "../news/第一财经板块对应新闻-0423-1.csv\n",
      "../news/东方财富网---个股要闻-TO600689.csv\n",
      "../news/第一财经板块对应新闻-0419-2.csv\n",
      "../news/行业研究报告数据中心东方财富网-0502-1.csv\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "append_csv2txt('../news/')\n",
    "print('Loading CSV files took %fs!' % (time.time() - start_time)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 离线语料分析建模及板块预测模型优化\n",
    "\n",
    "LDA：\n",
    "\n",
    "* 生成语料库（初期由csv文件生成，后期由数据集中获取）\n",
    "* 读取语料库（每行一条资讯，已分词，空格分隔）\n",
    "* 利用语料库训练LDA模型并保存\n",
    "\n",
    "RF：\n",
    "\n",
    "* 读取标记数据库（每行一条资讯，第一列为标签，第二列为资讯，已分词，空格分隔）\n",
    "* 利用LDA模型转换资讯为Vector-标记 格式\n",
    "* 训练RF模型并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新闻爬取xlxs文件目录：\n",
    "NEWS_PATH = '../news/'\n",
    "#语料库文件路径：\n",
    "DATA_PATH = '../data/news_words.txt'\n",
    "#标记数据路径\n",
    "LABEL_PATH = '../labels/'\n",
    "# LDA Model 路径：\n",
    "LDA_PATH = '../model/lda.model'\n",
    "\n",
    "#coding=utf-8  \n",
    "import codecs  \n",
    "from gensim import corpora  \n",
    "from gensim.models import LdaModel  \n",
    "from gensim.corpora import Dictionary  \n",
    "\n",
    "\n",
    "import jieba\n",
    "import csv\n",
    "import numpy as np  \n",
    "import os  \n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "   \n",
    "import time    \n",
    "from sklearn import metrics    \n",
    "import pickle as pickle    \n",
    "import pandas as pd  \n",
    "  \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料库载入及LDA模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历语料库文件，逐步增加dictionary\n",
    "print(\"Start reading corpus file...\")\n",
    "start_time = time.time()    \n",
    "fr=open(DATA_PATH,'r')  \n",
    "train=[]  \n",
    "dictionary = corpora.Dictionary()\n",
    "for line in fr.readlines():  \n",
    "    line=line.split(' ')  \n",
    "    dictionary.add_documents([line]) \n",
    "dictionary.doc2bow([\"军工\",\"金融\"])\n",
    "print('Composing dictionary took %fs!' % (time.time() - start_time)) \n",
    "start_time = time.time()\n",
    "corpus = [ dictionary.doc2bow(text) for text in train ]  \n",
    "print('Loading corpus took %fs!' % (time.time() - start_time)) \n",
    "\n",
    "#训练LDA模型\n",
    "start_time = time.time()    \n",
    "lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=200)  \n",
    "lda.save(LDA_PATH)\n",
    "print('LDA training took %fs!' % (time.time() - start_time)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-05-07'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = time.strftime('%Y-%m-%d',time.localtime())\n",
    "os.rename(LDA_PATH,LDA_PATH+today)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
