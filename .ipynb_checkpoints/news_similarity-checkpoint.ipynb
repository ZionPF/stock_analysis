{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.879 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 1h news success\n",
      "totally cost 327s\n",
      "dictionary success\n",
      "corpus success\n",
      "tfidf success\n",
      "分词结果：\n",
      "['孙', '公司', '海航', '地产', '拟', '海南', '融创昌晟', '签订', '股权', '转让', '协议', '出售', '海航', '地产', '持有', '海岛', '物流', '股权', '转让', '价款', '约', '7.97', '亿元', '海航', '地产', '拟', '出售', '持有', '海南', '高', '房地', '地产', '房地产', '开发', '有限', '公司', '有限公司', '股权', '海南', '融创昌晟', '转让', '价款', '约', '11.36', '亿元', '责任', '编辑', '责任编辑', '张恒']\n",
      "similarity success\n",
      "totally cost 3s\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "import word_segmentation as ws\n",
    "\n",
    "def load_1h_news():\n",
    "    \"\"\"\n",
    "    加载过去一小时内的所有新闻\n",
    "    \"\"\"\n",
    "    global all_doc_list #1小时时间窗口的历史新闻数据分词结果列表[timestamp+title+content,]\n",
    "    \n",
    "    #每次加载新一小时的数据，清空之前的all_doc_list列表\n",
    "    all_doc_list = []\n",
    "    \n",
    "    # 数据库通过时间范围查询获取一小时的新闻纪录放入all_doc[timestamp+title+content,]\n",
    "    # 测试代码，使用../data/news0312.csv作为一小时时间窗口的历史新闻数据\n",
    "    file_data = pd.read_csv('/data/jupyter/stock/data/news0312.csv')\n",
    "    #stop_words = ws.stopwordslist('/data/jupyter/stock/utils/stopwords.txt')\n",
    "    for index, row in file_data.iterrows():\n",
    "        row_words = ws.word_segmentation(str(row.title) + ',' + str(row.content))\n",
    "        all_doc_list.append(row_words)\n",
    "    print(\"load 1h news success\")\n",
    "\n",
    "def tf_idf_model():\n",
    "    \"\"\"\n",
    "    根据过去一小时内的所有新闻数据建立tf-idf模型\n",
    "    \"\"\"\n",
    "    global dictionary # 词袋\n",
    "    global corpus # 语料库\n",
    "    global tfidf # tf-idf模型\n",
    "    \n",
    "    # 使用dictionary方法获取词袋（bag-of-words）\n",
    "    dictionary = corpora.Dictionary(all_doc_list)\n",
    "    print(\"dictionary success\")\n",
    "    \n",
    "    # 使用doc2bow制作语料库（一组向量），向量中的每个元素是一个二元组（编号、频次数），对应分词后文档的每个词\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in all_doc_list]\n",
    "    print(\"corpus success\")\n",
    "    \n",
    "    # 使用TF-IDF模型对语料库建模\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    print(\"tfidf success\")\n",
    "\n",
    "def news_similarity(news_seg):\n",
    "    \"\"\"\n",
    "    读取一条新闻的标题和正文，计算该新闻与历史新闻数据的相似度并标记\n",
    "    input: 新闻的标题和正文分词结果（list）\n",
    "    return：是否重复的标记（int）\n",
    "    \"\"\"\n",
    "    # 使用doc2bow将新推送的新闻转换为二元组的向量\n",
    "    news_vec = dictionary.doc2bow(news_seg)\n",
    "    \n",
    "    # 对corpus语料库中的每个目标文档计算文档的相似度\n",
    "    index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=len(dictionary.keys()))\n",
    "    sim = index[tfidf[news_vec]]\n",
    "    print(\"similarity success\")\n",
    "    \n",
    "    # 如果有相似度在90%以上的文档存在，即将新推送的新闻标记为1，否则0\n",
    "    repeat =1 if sim.max(axis=0) >= 0.95 else 0\n",
    "    \n",
    "    return repeat\n",
    "\n",
    "def add_news(news_seg):\n",
    "    \"\"\"\n",
    "    将新推送的新闻添加至历史数据列表及语料库中\n",
    "    \"\"\"\n",
    "    # 新增推送新闻至all_doc_list（一小时时间窗口历史数据分词结果列表）\n",
    "    all_doc_list.append(news_seg)\n",
    "    # 新增推送新闻所建立的向量至corpus语料库\n",
    "    corpus.append(dictionary.doc2bow(news_seg))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 首先加载数据库中的一小时新闻历史数据\n",
    "    time_start = time.time()\n",
    "    load_1h_news()\n",
    "    time_elapsed = time.time() - time_start\n",
    "    print('totally cost {:.0f}s'.format(time_elapsed))\n",
    "    \n",
    "    \n",
    "    # 建立TF-IDF模型\n",
    "    tf_idf_model()\n",
    "    \n",
    "    time_start = time.time()\n",
    "    # 新推送的新闻\n",
    "    str_title_content = \"孙公司海航地产拟与海南融创昌晟签订《股权转让协议》，出售海航地产所持有的海岛物流100%的股权，转让价款约7.97亿元；同时，海航地产拟出售所持有的海南高和房地产开发有限公司100%的股权至海南融创昌晟，转让价款约11.36亿元。责任编辑：张恒\"\n",
    "\n",
    "    # 新闻分词\n",
    "    news_seg = ws.word_segmentation(str_title_content)\n",
    "    \n",
    "    print(\"分词结果：\")\n",
    "    print(news_seg)\n",
    "    \n",
    "    # 计算文档相似度\n",
    "    repeat = news_similarity(news_seg)\n",
    "    \n",
    "    time_elapsed = time.time() - time_start\n",
    "    print('totally cost {:.0f}s'.format(time_elapsed))\n",
    "    # 将新推送的新闻添加至历史数据列表及语料库中\n",
    "    add_news(news_seg)\n",
    "    print(repeat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词结果：\n",
      "['海航', '基础', '海航基础', '海航', '地产', '拟', '作价', '19.33', '亿向', '融创', '出售', '两', '公司', '新浪', '财经', '讯', '月', '12', '日', '消息', '海航', '基础', '海航基础', '600515', '月', '12', '日', '晚间', '公告', '孙', '公司', '海航', '地产', '拟', '海南', '融创昌晟', '签订', '股权', '转让', '协议', '出售', '海航', '地产', '持有', '海岛', '物流', '股权', '转让', '价款', '约', '7.97', '亿元', '海航', '地产', '拟', '出售', '持有', '海南', '高', '房地', '地产', '房地产', '开发', '有限', '公司', '有限公司', '股权', '海南', '融创昌晟', '转让', '价款', '约', '11.36', '亿元', '责任', '编辑', '责任编辑', '张恒']\n",
      "similarity success\n",
      "totally cost 3s\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "# 新推送的新闻\n",
    "str_title_content = \"海航基础：海航地产拟作价19.33亿向融创出售两公司，新浪财经讯 3月12日消息，海航基础（600515）3月12日晚间公告，孙公司海航地产拟与海南融创昌晟签订《股权转让协议》，出售海航地产所持有的海岛物流100%的股权，转让价款约7.97亿元；同时，海航地产拟出售所持有的海南高和房地产开发有限公司100%的股权至海南融创昌晟，转让价款约11.36亿元。责任编辑：张恒\"\n",
    "\n",
    "# 新闻分词\n",
    "news_seg = ws.word_segmentation(str_title_content)\n",
    "\n",
    "print(\"分词结果：\")\n",
    "print(news_seg)\n",
    "\n",
    "# 计算文档相似度\n",
    "repeat = news_similarity(news_seg)\n",
    "\n",
    "time_elapsed = time.time() - time_start\n",
    "print('totally cost {:.0f}s'.format(time_elapsed))\n",
    "# 将新推送的新闻添加至历史数据列表及语料库中\n",
    "add_news(news_seg)\n",
    "print(repeat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
